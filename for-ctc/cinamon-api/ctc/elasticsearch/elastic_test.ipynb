{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import difflib\n",
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import requests\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "\n",
    "\n",
    "def preprocess_data(csv_path):\n",
    "    df = pd.read_csv(csv_path, converters={'銀行コード':str, '郵便番号':str, '地名': str, '口座番号': str})\n",
    "    df = df.replace('\\n','', regex=True)\n",
    "    df.fillna(axis=1,value='',inplace=True)\n",
    "    dir_path = os.path.dirname(csv_path)\n",
    "    filename, _ = os.path.splitext(os.path.basename(csv_path))\n",
    "    output = os.path.join(dir_path,'data_'+ os.path.basename(csv_path))\n",
    "    alternatives = {\n",
    "            '名称 1': 'company_name_1' ,\n",
    "            '名称 2': 'company_name_2',\n",
    "            '名称 3': 'company_name_3',\n",
    "            '名称 4': 'company_name_4', \n",
    "            '地名': 'company_address' ,\n",
    "            '電話番号' :'tel' ,\n",
    "            'FAX番号' : 'fax',\n",
    "            '仕入先ｺｰﾄﾞ': 'company_id',\n",
    "            '銀行コード': 'bank_branch_id',\n",
    "            '口座番号': 'account',\n",
    "            '種別': 'type_of_account',\n",
    "            '口座名義人名': 'account_name'\n",
    "        }\n",
    "    for _jp, _en in alternatives.items():\n",
    "        df.rename(columns = {'{}'.format(_jp):'{}'.format(_en)}, inplace = True)\n",
    "    for column in df.columns:\n",
    "        if column == 'tel' or column == 'fax':\n",
    "            df[column] = df[column].map(lambda x: ''.join([i for i in str(x) if i.isdigit()]))\n",
    "            df[column] = df[column].map(lambda x: unicodedata.normalize('NFKC', str(x)))\n",
    "            df[column] = df[column].map(lambda x:  str(x).replace('',' ').strip())\n",
    "        elif column == 'company_id':\n",
    "            df[column] = df[column].map(lambda x: unicodedata.normalize('NFKC', str(x)))\n",
    "        elif column == 'account':\n",
    "            df[column] = df[column].apply(lambda x : x[::-1]) #reverse account number\n",
    "            df[column] = df[column].map(lambda x: unicodedata.normalize('NFKC', str(x)))\n",
    "            df[column] = df[column].map(lambda x:  str(x).replace(' ',''))\n",
    "            df[column] = df[column].map(lambda x:  str(x).replace('',' ').strip())\n",
    "        else:\n",
    "            df[column] = df[column].map(lambda x: unicodedata.normalize('NFKC', str(x)))\n",
    "            df[column] = df[column].map(lambda x:  str(x).replace(' ',''))\n",
    "            df[column] = df[column].map(lambda x:  str(x).replace('',' ').strip())\n",
    "    df.to_csv(output, sep=',', encoding='utf-8', index=False)\n",
    "    return output, filename\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as json_data:\n",
    "        ocr_result = json.load(json_data)\n",
    "    return ocr_result\n",
    "\n",
    "class MizuhoElastic:\n",
    "    def __init__(self, debug = False):\n",
    "        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "        self.company_result = {}\n",
    "        self.bank_result = {}\n",
    "        self.company_json = {}\n",
    "        self.bank_json = {}\n",
    "        self.debug = debug\n",
    "        self.indexs = {\n",
    "            'company_information': ['company_name', 'company_address', 'tel', 'fax'],\n",
    "            'bank_information': ['banks']\n",
    "        }\n",
    "    \n",
    "    def find_index(self, field):\n",
    "        index_out = ''\n",
    "        for index, fields in self.indexs.items():\n",
    "            if field in fields:\n",
    "                index_out = index\n",
    "                break\n",
    "        return index_out\n",
    "    \n",
    "    def normalize_output(self, old_string):\n",
    "        new_string = unicodedata.normalize('NFKC', old_string.replace(' ', '').strip())\n",
    "        return new_string\n",
    "    \n",
    "    def normalize_input(self, old_string):\n",
    "        new_string = unicodedata.normalize('NFKC', old_string.replace(' ', ''))\n",
    "        new_string = unicodedata.normalize('NFKC', new_string.replace('', ' ').strip())\n",
    "        return new_string\n",
    "    \n",
    "    def import_data(self, csv_path):\n",
    "        data_path, index = preprocess_data(csv_path)\n",
    "        with open(data_path) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            helpers.bulk(self.es, reader, index=index, doc_type='mizuho')\n",
    "    \n",
    "    def search_a_field(self, index, type_field, value_field):\n",
    "        value_field = self.normalize_input(value_field)\n",
    "        body = {\"query\": {\"match\": {\"{}\".format(type_field): '{}'.format(value_field)}}}\n",
    "        res = self.es.search(index=index, doc_type='mizuho', body=body)\n",
    "        res = res['hits']['hits']\n",
    "        _ids = {}\n",
    "        if res:\n",
    "            for result in res:\n",
    "                _score = 0.0\n",
    "                value_search =  self.normalize_output(result['_source']['{}'.format(type_field)])\n",
    "                diff = difflib.SequenceMatcher(None, self.normalize_output(value_field), value_search)\n",
    "                _score = diff.ratio()\n",
    "                if _score > 0.7:\n",
    "                    _ids[result['_source']['company_id']] = _score\n",
    "        return _ids\n",
    "    \n",
    "    def search_multiple_fields(self, index, type_field, value_field):\n",
    "        value_field = self.normalize_input(value_field)\n",
    "        print(value_field)\n",
    "        body =  {\"query\": {\"multi_match\":{\n",
    "            \"fields\": [\"{}*\".format(type_field)],\n",
    "            \"query\" : \"{}\".format(value_field)\n",
    "        }}}\n",
    "        res = self.es.search(index=index, doc_type='mizuho', body=body)\n",
    "        res = res['hits']['hits']\n",
    "        _ids = {}\n",
    "        if res:\n",
    "            for result in res:\n",
    "                _score = 0.0\n",
    "                for _field, _value in result['_source'].items():\n",
    "                    if _field.startswith('{}'.format(type_field)):\n",
    "                        value_search =  self.normalize_output(result['_source']['{}'.format(_field)])\n",
    "                        diff = difflib.SequenceMatcher(None, self.normalize_output(value_field), value_search)\n",
    "                        if diff.ratio() > 0.7 and diff.ratio() > _score:\n",
    "                            _score = diff.ratio()\n",
    "                            _ids[result['_source']['company_id']] = _score\n",
    "        return _ids\n",
    "\n",
    "    def search_company_fields(self):\n",
    "        if any([v for k, v in self.company_result.items()]):\n",
    "            _ids = self.company_true_id()\n",
    "            if _ids is not None:\n",
    "                _id = _ids[0]\n",
    "                self.company_id = _id\n",
    "                body = {\"query\": {\"term\": {\"company_id\": \"{}\".format(self.company_id)}}}\n",
    "                result_from_id = self.es.search(index='company_information', doc_type='mizuho', body= body)\n",
    "                result_from_id = result_from_id['hits']['hits'][0]\n",
    "                if result_from_id.get('_source'):\n",
    "                    _score_company_name = 0\n",
    "                    for field, value_field in self.company_result.items():\n",
    "                        if field.startswith('company_name'):\n",
    "                            fields = [i for i in result_from_id['_source'].keys() if i.startswith('company_name')]\n",
    "                            for field_result in fields:\n",
    "                                _diff = difflib.SequenceMatcher(None, self.normalize_output(result_from_id['_source'][field_result]), \n",
    "                                                            self.company_json['company_name'])\n",
    "                                _score = _diff.ratio( ) \n",
    "                                if _score > _score_company_name:\n",
    "                                    self.company_result['company_name'] = self.normalize_output(result_from_id['_source'][field_result])\n",
    "                                    _score_company_name = _score\n",
    "                            continue\n",
    "                        self.company_result[field] =  self.normalize_output(result_from_id['_source'][field])\n",
    "        return self.company_result\n",
    "            \n",
    "    def company_true_id(self):\n",
    "        _total_ids = []\n",
    "        _ids = set([i for k,v in self.company_result.items() for i in v.keys()])\n",
    "        for _id in _ids:\n",
    "            _count = sum([1 for k,v in self.company_result.items() for i in v.keys() if i == _id])\n",
    "            _score = sum([v[i] for k,v in self.company_result.items() for i in v.keys() if i == _id])\n",
    "            _total_ids.append((_id, _count, _score))    # (id, _count, _total_score)\n",
    "        _total_ids = sorted(_total_ids, key=itemgetter(1,2), reverse=True)    # sorting _count to _total_score\n",
    "        if len(_total_ids) > 0:\n",
    "            return _total_ids[0]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def search_bank_fields(self):\n",
    "        if self.company_id:\n",
    "            body = {\"query\": {\"term\": {\"company_id\": \"{}\".format(self.company_id)}}}\n",
    "            result_from_id = self.es.search(index='company_information', doc_type='mizuho', body= body)\n",
    "            result_from_id = result_from_id['hits']['hits']\n",
    "            if result_from_id:\n",
    "                for _index, result in enumerate(result_from_id):\n",
    "                    self.bank_result['bank'+ str(_index+1)] = {\n",
    "                        'bank': self.normalize_output(result['_source']['bank_branch_id'])[:4],\n",
    "                        'branch': self.normalize_output(result['_source']['bank_branch_id'])[4:],\n",
    "                        'type_of_account': self.normalize_output(result['_source']['type_of_account']),\n",
    "                        'account': self.normalize_output(result['_source']['account'])[::-1],\n",
    "                    }\n",
    "            print(self.bank_result)\n",
    "        else:\n",
    "            for bank in self.bank_json:\n",
    "                _value_account = self.bank_json[bank][::-1]\n",
    "                body = {\"query\": {\"term\": {\"account\": \"{}\".format(_value_account)}}}\n",
    "                result_from_id = self.es.search(index='company_information', doc_type='mizuho', body= body)\n",
    "                \n",
    "                \n",
    "    def run(self,json_input):\n",
    "        print('SPLITTING SJON INPUT')\n",
    "        self.company_json = {}\n",
    "        self.bank_json = {}\n",
    "        for field, value_field in json_input.items():\n",
    "            index = self.find_index(field)\n",
    "            if index.startswith('company_information'):\n",
    "                self.company_json[field] = value_field\n",
    "                if field.startswith('company_name'):\n",
    "                    self.company_result[field] = self.search_multiple_fields(index, 'company_name' ,value_field)\n",
    "                    continue\n",
    "                self.company_result[field] = self.search_a_field('company_information', field, value_field)\n",
    "            else:\n",
    "                self.bank_json[field] = value_field\n",
    "        print(self.search_company_fields())\n",
    "    \n",
    "    def delete_elastic(self):\n",
    "        os.system('curl -XDELETE localhost:9200/mizuho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input = {\n",
    "    'company_name':'芙蓉オートリース株式会社',\n",
    "    'company_address':'',\n",
    "    'tel':'',\n",
    "    'fax':'',\n",
    "    'bank1': {\n",
    "                 'bank': 'みずほ銀行',\n",
    "                 'branch': '東京中央支店',\n",
    "                 'type_of_account': '',\n",
    "                 'account': '566',\n",
    "             },\n",
    "    'bank2': {\n",
    "                 'bank': 'みずq',\n",
    "                 'branch': '東京中央支店',\n",
    "                 'type_of_account': '',\n",
    "                 'account': '309',\n",
    "             }\n",
    "}\n",
    "mizuho = MizuhoElastic(debug=True)\n",
    "mizuho.import_data('/Users/duongthanh/Documents/Mizuho_2/company_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mizuho.search_a_field('company_information', 'tel', '03853304')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING SJON INPUT\n",
      "芙 蓉 オ ー ト リ ー ス 株 式 会 社\n",
      "{'company_name': '芙蓉オートリース株式会社', 'company_address': '〒102-0073九段北1―13―5ヒューリック九段ビル11階千代田区', 'tel': '0366852411', 'fax': ''}\n"
     ]
    }
   ],
   "source": [
    "mizuho.run(json_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bank1': {'bank': 'みずほ銀行',\n",
       "  'branch': '東京中央支店',\n",
       "  'type_of_account': '',\n",
       "  'account': '566'},\n",
       " 'bank2': {'bank': 'みずq',\n",
       "  'branch': '東京中央支店',\n",
       "  'type_of_account': '',\n",
       "  'account': '309'}}"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mizuho.company_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bank1': {'bank': '0001', 'branch': '125', 'type_of_account': '1', 'account': '1395309'}}\n"
     ]
    }
   ],
   "source": [
    "mizuho.search_bank_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "body = {\"query\": {\"regexp\": {\"account\": {\"value\": \"9 0 ~ 1\",\"flags\": \"COMPLEMENT|INTERVAL\"}}}}\n",
    "# body={\"query\": {\"wildcard\" : { \"account\" : \"9 0 3*1\" }}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': 0, 'max_score': None, 'hits': []}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(index='company_information', doc_type='mizuho', body= body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.match('^[0-9]{4}369$','12334369')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^[0-9]{3}1931$'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = '^[0-9]{%d}%d$' %(3,1931); condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
